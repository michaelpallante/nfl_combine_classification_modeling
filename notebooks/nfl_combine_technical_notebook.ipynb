{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NFL Combine Classification Modeling\n",
    "\n",
    "## Technical Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Goals\n",
    "\n",
    "- Determine the influence the NFL Combine has on a lineman (offensive linemen and defensive linemen) prospect's draft status (getting drafted or not).\n",
    "- Reveal how much the NFL Combine factors in on a lineman (offensive linemen and defensive linemen) prospect's draft value (how early or how late a prospect gets drafted, if at all).\n",
    "- Discover which NFL Combine drills have the most impact on a lineman (offensive linemen and defensive linemen) prospect's draft position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Data\n",
    "\n",
    "The dataset that was analyzed for this study contains 9,544 observations of NFL Combine and NFL Draft data, dating from 1987-2017. The NFL Combine data primarily displays the performance of players over that time period in combine drills. The NFL Draft data contains the draft pick information of players from that time span, including what round they were selected in and the team that picked them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelpallante/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Import libraries\n",
    "%run ../python_files/libraries\n",
    "%matplotlib inline\n",
    "# from libraries import *   #for use within .py file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import cleaned data from our exploratory data analysis\n",
    "%run ../python_files/nfl_combine_eda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "##### Pre-Modeling Techniques\n",
    "\n",
    "- Scaling: We use Standard Scaler to scale our 'x' training and test datasets so that our model does not unfairly penalize our coefficients due to differences in units.\n",
    "\n",
    "- Resampling: We use SMOTE, as this method creates synthetic samples for minority classes. This will oversample the minority classes and thus, add more balance to our model.\n",
    "\n",
    "##### Model Implementation and Model Performance\n",
    "\n",
    "We utilized a pipeline technique to implement 8 different model types:\n",
    "\n",
    "- Logistic Regression\n",
    "- KNN\n",
    "- SVC\n",
    "- NuSVC\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- Ada Boost\n",
    "- Gradient Boosting\n",
    "\n",
    "After running our pipeline, we will be able to review model performance using accuracy as our primary metric, as well as confusion matrices to review correct predictions vs incorrect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False) \n",
      "\n",
      "          predicted 0  predicted 1\n",
      "actual 0          251          562\n",
      "actual 1          151         1514 \n",
      "\n",
      "model score: 0.712 \n",
      "\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
      "                     weights='uniform') \n",
      "\n",
      "          predicted 0  predicted 1\n",
      "actual 0          478          335\n",
      "actual 1          150         1515 \n",
      "\n",
      "model score: 0.804 \n",
      "\n",
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False) \n",
      "\n",
      "          predicted 0  predicted 1\n",
      "actual 0          247          566\n",
      "actual 1           76         1589 \n",
      "\n",
      "model score: 0.741 \n",
      "\n",
      "NuSVC(break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "      decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "      max_iter=-1, nu=0.5, probability=True, random_state=None, shrinking=True,\n",
      "      tol=0.001, verbose=False) \n",
      "\n",
      "          predicted 0  predicted 1\n",
      "actual 0          526          287\n",
      "actual 1           62         1603 \n",
      "\n",
      "model score: 0.859 \n",
      "\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=13, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best') \n",
      "\n",
      "          predicted 0  predicted 1\n",
      "actual 0          659          154\n",
      "actual 1           22         1643 \n",
      "\n",
      "model score: 0.929 \n",
      "\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=13, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False) \n",
      "\n",
      "          predicted 0  predicted 1\n",
      "actual 0          710          103\n",
      "actual 1            0         1665 \n",
      "\n",
      "model score: 0.958 \n",
      "\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
      "                   n_estimators=50, random_state=None) \n",
      "\n",
      "          predicted 0  predicted 1\n",
      "actual 0          288          525\n",
      "actual 1          149         1516 \n",
      "\n",
      "model score: 0.728 \n",
      "\n",
      "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='deprecated',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False) \n",
      "\n",
      "          predicted 0  predicted 1\n",
      "actual 0          358          455\n",
      "actual 1           77         1588 \n",
      "\n",
      "model score: 0.785 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model Selection and Comparison\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(),\n",
    "    NuSVC(probability=True),\n",
    "    DecisionTreeClassifier(max_depth = 13),\n",
    "    RandomForestClassifier(max_depth = 13),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier()\n",
    "    ]\n",
    "for classifier in classifiers:\n",
    "    pipe = Pipeline([\n",
    "                     ('ss', StandardScaler()),\n",
    "                     ('classifier', classifier)])\n",
    "    pipe.fit(x_train_ds, y_train_ds)   \n",
    "    print(classifier, '\\n')\n",
    "    conf_matrix = pd.DataFrame(confusion_matrix(y_train_ds, pipe.predict(x_train_ds)),\n",
    "                           index = ['actual 0', 'actual 1'], \n",
    "                           columns = ['predicted 0', 'predicted 1'])\n",
    "    print(conf_matrix, '\\n')\n",
    "    print(\"model score: %.3f\" % pipe.score(x_train_ds, y_train_ds), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Implementation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logit_model = sm.Logit(y_train_log, x_train_log)\n",
    "# logit_result = logit_model.fit()\n",
    "# print(logit_result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Fitting\n",
    "\n",
    "We use our model from above, which was built on the training data set, to test against our test data set below. This will help us evaluate the model performance of our logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logreg_model = LogisticRegression()\n",
    "# logreg_model.fit(x_train_log, y_train_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predicting Test Set Results and Calculating Accuracy\n",
    "\n",
    "Below, we use several metrics to evaluate the model performance of our logistic regression model, including the calculation of accuracy, a confusion matrix, a classification report, and a plot of a ROC curve. These performance evaluation techniques evaluate the training dataset against the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_log = logreg_model.predict(x_test_log)\n",
    "# print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg_model.score(x_test_log, y_test_log)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through the calculation of the accuracy, 78% of the variability in 'crash' can be explained using our feature variables, which is promising."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matrix\n",
    "\n",
    "The below confusion matrix results are telling us that we have 946 (830 + 116 = 946) correct predictions and 263 (200 + 63 = 263) incorrect predictions. The ratio of approximately 3.6 correct predictions to every 1 incorrect predictions is a good sign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix = confusion_matrix(y_test_log, y_pred_log)\n",
    "# print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "\n",
    "logit_roc_auc = roc_auc_score(y_test_log, logreg_model.predict(x_test_log))\n",
    "fpr, tpr, thresholds = roc_curve(y_test_log, logreg_model.predict_proba(x_test_log)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Conclusions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
