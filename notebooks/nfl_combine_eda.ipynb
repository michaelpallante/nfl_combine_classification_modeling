{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NFL Combine Classification Modeling\n",
    "\n",
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Goals\n",
    "\n",
    "- Determine the influence the NFL Combine has on a prospect getting drafted or not.\n",
    "- Determine the influence the NFL Combine has in terms of how early or how late a prospect gets drafted.\n",
    "- Discover which NFL Combine drills have the most impact on a prospect's draft status."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Data\n",
    "\n",
    "The dataset that was analyzed for this study contains 10,228 observations of NFL Combine data, dating from 1987-2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "# %run ../python_files/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import and Data Examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import data\n",
    "#  = pd.read_csv('../data/.csv')\n",
    "\n",
    "# quick overview of the dataset\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick review of the variables in the dataset\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# quick review of the characteristics of our current continuous variables in the dataset\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the number of NaN values in the dataset\n",
    "# df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning, Data Transformations, and Data Exploration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy values for the categorical variables\n",
    "\n",
    "# auto_df['mstatus'] = auto_df['mstatus'].map({'Yes': 1, 'No': 0})\n",
    "# auto_df['sex'] = auto_df['sex'].map({'M': 1, 'F': 0})\n",
    "# auto_df['education'] = auto_df['education'].map({'<High School': 0, 'High School': 0, 'Bachelors': 1, 'Masters': 1, 'PhD': 1})\n",
    "# auto_df['job'] = auto_df['job'].map({'Student': 1, 'Blue Collar': 0, 'Clerical': 0, 'Doctor': 0, 'Home Maker': 0, 'Lawyer': 0, 'Manager': 0, 'Professional': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Transformations for non-normalized variables. Then, drop the original variable from the dataset.\n",
    "\n",
    "# def log_col(df, col):\n",
    "#     '''Convert column to log values and\n",
    "#     drop the original column\n",
    "#     '''\n",
    "#     df[f'{col}_log'] = np.log(df[col])\n",
    "#     df.drop(col, axis=1, inplace=True)\n",
    "\n",
    "# log_col(auto_df, 'tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# quick review of the characteristics of all variables in the dataset, \n",
    "# including the new dummy variables and log-transformed variables\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlations between all variables in auto_df dataset\n",
    "# df.corr(method = 'pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation Heatmap of all variables in auto_df dataset\n",
    "\n",
    "# mask = np.zeros_like(auto_df.corr())\n",
    "# triangle_indices = np.triu_indices_from(mask)\n",
    "# mask[triangle_indices] = True\n",
    "\n",
    "# plt.figure(figsize=(35,30))\n",
    "# ax = sns.heatmap(auto_df.corr(method='pearson'), cmap=\"coolwarm\", mask=mask, annot=True, annot_kws={\"size\": 18}, square=True, linewidths=4)\n",
    "# sns.set_style('white')\n",
    "# plt.xticks(fontsize=14, rotation=45)\n",
    "# plt.yticks(fontsize=14, rotation=0)\n",
    "# bottom, top = ax.get_ylim()\n",
    "# ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Train and Test Dataset Creation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split auto_insurance_df into train and test datasets for our logistic and linear regression models\n",
    "\n",
    "#train and test datasets for logistic regression model\n",
    "# crash = auto_df['crash']\n",
    "# features_log = auto_df.drop(['crash', 'crash_cost'], axis = 1)\n",
    "# x_train_log, x_test_log, y_train_log, y_test_log = train_test_split(features_log, crash, test_size = 0.2, random_state = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "For modeling purposes, we used recursive feature elimination for both our logistic regression model and our simple linear regression model. This process uses cross-validation techniques, using accuracy as a metric, to eliminate variables that may hurt our model performance. Those variables get dropped from the dataset prior to modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination for Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logreg_model = LogisticRegression()\n",
    "# rfecv_log = RFECV(estimator=logreg_model, step=1, cv=StratifiedKFold(10), scoring='accuracy')\n",
    "# rfecv_log.fit(x_train_log, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# feature_importance_log = list(zip(features_log, rfecv_log.support_))\n",
    "# new_features_log = []\n",
    "# for key,value in enumerate(feature_importance_log):\n",
    "#     if(value[1]) == True:\n",
    "#         new_features_log.append(value[0])\n",
    "        \n",
    "# print(new_features_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linreg_model = LinearRegression()\n",
    "# rfecv_lin = RFECV(estimator=linreg_model, step=1, min_features_to_select = 1, scoring='r2')\n",
    "# rfecv_lin.fit(x_train_lin, y_train_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# feature_importance_lin = list(zip(features_lin, rfecv_lin.support_))\n",
    "# new_features_lin = []\n",
    "# for key,value in enumerate(feature_importance_lin):\n",
    "#     if(value[1]) == True:\n",
    "#         new_features_lin.append(value[0])\n",
    "        \n",
    "# print(new_features_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Train and Test Datasets after Feature Selection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final train and test datasets for logistic regression model\n",
    "# x_train_log = x_train_log[new_features_log]\n",
    "# x_test_log = x_test_log[new_features_log]\n",
    "\n",
    "# print(x_train_log.shape)\n",
    "# print(x_test_log.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
